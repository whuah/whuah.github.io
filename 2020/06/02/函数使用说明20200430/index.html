<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>函数使用说明20200430 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="机器学习记录  学习神经网络的时候，网上的数据集已经分割成了batch，训练的时候直接使用batch.next()就可以获取batch，但是有的时候需要使用自己的数据集，然而自己的数据集不是batch形式，就需要将其转换为batch形式，本文将介绍一个将数据打包成batch的方法。   tf.slice_input_producer（）  &#96;&#96;&#96;tf.slice_input_producer(t">
<meta property="og:type" content="article">
<meta property="og:title" content="函数使用说明20200430">
<meta property="og:url" content="http://yoursite.com/2020/06/02/%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E20200430/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="机器学习记录  学习神经网络的时候，网上的数据集已经分割成了batch，训练的时候直接使用batch.next()就可以获取batch，但是有的时候需要使用自己的数据集，然而自己的数据集不是batch形式，就需要将其转换为batch形式，本文将介绍一个将数据打包成batch的方法。   tf.slice_input_producer（）  &#96;&#96;&#96;tf.slice_input_producer(t">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-06-02T10:07:53.019Z">
<meta property="article:modified_time" content="2020-04-28T09:57:31.697Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-函数使用说明20200430" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/06/02/%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E20200430/" class="article-date">
  <time datetime="2020-06-02T10:07:53.019Z" itemprop="datePublished">2020-06-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      函数使用说明20200430
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<h4 id="机器学习记录"><a href="#机器学习记录" class="headerlink" title="机器学习记录"></a>机器学习记录</h4></blockquote>
<ol>
<li>学习神经网络的时候，网上的数据集已经分割成了batch，训练的时候直接使用batch.next()就可以获取batch，但是有的时候需要使用自己的数据集，然而自己的数据集不是batch形式，就需要将其转换为batch形式，本文将介绍一个将数据打包成batch的方法。</li>
</ol>
<ul>
<li><p><strong>tf.slice_input_producer（）</strong></p>
</li>
<li><p>```<br>tf.slice_input_producer(tensor_list, num_epochs=None, shuffle=True, seed=None,</p>
<pre><code>capacity=32, shared_name=None, name=None)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 从输入的tensor_list按要求抽取一个tensor放入文件名队列，下面解释下各个参数：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">import torch.utils.data as data</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import torchvision  #数据库模块</span><br><span class="line">import h5py</span><br><span class="line">import numpy as np</span><br><span class="line">from keras.utils import to_categorical</span><br><span class="line"></span><br><span class="line">torch.manual_seed(1) #reproducible</span><br><span class="line">#Hyper Parameters</span><br><span class="line">EPOCH &#x3D; 1</span><br><span class="line">BATCH_SIZE &#x3D; 50</span><br><span class="line">LR &#x3D; 0.001</span><br><span class="line">data_folder &#x3D; &#39;data1&#x2F;&#39;</span><br><span class="line">traindata_path &#x3D; data_folder + &#39;train.h5&#39;</span><br><span class="line">testdata_path &#x3D; data_folder + &#39;test.h5&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data &#x3D; torchvision.datasets.MNIST(</span><br><span class="line">    root&#x3D;&#39;&#x2F;mnist&#x2F;&#39;, #保存位置</span><br><span class="line">    train&#x3D;True, #training set</span><br><span class="line">    transform&#x3D;torchvision.transforms.ToTensor(), #converts a PIL.Image or numpy.ndarray</span><br><span class="line">                                        #to torch.FloatTensor(C*H*W) in range(0.0,1.0)</span><br><span class="line">    download&#x3D;True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data &#x3D; torchvision.datasets.MNIST(root&#x3D;&#39;&#x2F;MNIST&#x2F;&#39;)</span><br><span class="line">#如果是普通的Tensor数据，想使用torch_dataset &#x3D; data.TensorDataset(data_tensor&#x3D;x, target_tensor&#x3D;y)</span><br><span class="line">#将Tensor转换成torch能识别的dataset</span><br><span class="line">#批训练， 50 samples, 1 channel, 28*28, (50, 1, 28 ,28)</span><br><span class="line">train_loader &#x3D; data.DataLoader(dataset&#x3D;train_data, batch_size&#x3D;BATCH_SIZE, shuffle&#x3D;True)</span><br><span class="line"></span><br><span class="line">test_x &#x3D; Variable(torch.unsqueeze(test_data.test_data, dim&#x3D;1), volatile&#x3D;True).type(torch.FloatTensor)[:2000]&#x2F;255.</span><br><span class="line">test_y &#x3D; test_data.test_lables[:2000]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def data_process(image_data,test_data,image_data_label,test_data_label,truelabel):</span><br><span class="line">    trainfile &#x3D; h5py.File(traindata_path,&#39;r&#39;)</span><br><span class="line">    testfile &#x3D; h5py.File(testdata_path,&#39;r&#39;)</span><br><span class="line"></span><br><span class="line">    image_data &#x3D; trainfile[&#39;test&#39;]#读取数据，读取data和label</span><br><span class="line">    test_data &#x3D; testfile[&#39;test&#39;]</span><br><span class="line">    image_data_label &#x3D; trainfile[&#39;test_label&#39;]</span><br><span class="line">    test_data_label &#x3D; testfile[&#39;test_label&#39;]</span><br><span class="line"></span><br><span class="line">    image_data &#x3D; image_data[:] &#x2F; 255 # normalize to 0~1</span><br><span class="line">    test_data &#x3D; test_data[:] &#x2F; 255#经过验证，可以。此时的data已经转变为列表了</span><br><span class="line">    image_data_label &#x3D; np.array(image_data_label[:])</span><br><span class="line">    test_data_label &#x3D; np.array(test_data_label[:])</span><br><span class="line">    #转换label的格式，转化为int类型，后面才可以用作index(1.前面标签应从0开始 2.现在手动转换)</span><br><span class="line">    image_data_label &#x3D; image_data_label.astype(&#39;int&#39;)</span><br><span class="line">    test_data_label &#x3D; test_data_label.astype(&#39;int&#39;)</span><br><span class="line">    truelabel &#x3D; test_data_label</span><br><span class="line"></span><br><span class="line">    image_data_label &#x3D; to_categorical(image_data_label)# convert to one-hot vectors</span><br><span class="line">    test_data_label &#x3D; to_categorical(test_data_label)</span><br><span class="line">    trainfile.close()</span><br><span class="line">    testfile.close()</span><br><span class="line">    return image_data,test_data,image_data_label,test_data_label,truelabel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class CNN(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.conv1 &#x3D; nn.Sequential(  # input shape (1,28,28)</span><br><span class="line">            nn.Conv2d(in_channels&#x3D;1,  # input height</span><br><span class="line">                      out_channels&#x3D;16,  # n_filter</span><br><span class="line">                      kernel_size&#x3D;5,  # filter size</span><br><span class="line">                      stride&#x3D;1,  # filter step</span><br><span class="line">                      padding&#x3D;2  # con2d出来的图片大小不变</span><br><span class="line">                      ),  # output shape (16,28,28)</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size&#x3D;2)  # 2x2采样，output shape (16,14,14)</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line">        self.conv2 &#x3D; nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32,7,7)</span><br><span class="line">                                   nn.ReLU(),</span><br><span class="line">                                   nn.MaxPool2d(2))</span><br><span class="line">        self.out &#x3D; nn.Linear(32 * 7 * 7, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x &#x3D; self.conv1(x)</span><br><span class="line">        x &#x3D; self.conv2(x)</span><br><span class="line">        x &#x3D; x.view(x.size(0), -1)  # flat (batch_size, 32*7*7)</span><br><span class="line">        output &#x3D; self.out(x)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">cnn &#x3D; CNN()</span><br><span class="line">print(cnn)</span><br><span class="line"></span><br><span class="line">#optimizer</span><br><span class="line">optimizer &#x3D; torch.optim.Adam(cnn.parameters(), lr&#x3D;LR)</span><br><span class="line"></span><br><span class="line">#loss_fun</span><br><span class="line">loss_func &#x3D; nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">#training loop</span><br><span class="line">for epoch in range(EPOCH):</span><br><span class="line">    for i, (x, y) in enumerate(train_loader):</span><br><span class="line">        batch_x &#x3D; Variable(x)</span><br><span class="line">        batch_y &#x3D; Variable(y)</span><br><span class="line">        #输入训练数据</span><br><span class="line">        output &#x3D; cnn(batch_x)</span><br><span class="line">        #计算误差</span><br><span class="line">        loss &#x3D; loss_func(output, batch_y)</span><br><span class="line">        #清空上一次梯度</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        #误差反向传递</span><br><span class="line">        loss.backward()</span><br><span class="line">        #优化器参数更新</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">test_output &#x3D;cnn(test_x[:10])</span><br><span class="line">pred_y &#x3D; torch.max(test_output,1)[1].data.numpy().squeeze()</span><br><span class="line">print(pred_y, &#39;prediction number&#39;)</span><br><span class="line">print(test_y[:10])</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/06/02/%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E20200430/" data-id="ckaxrnx41000230v4cjo050cr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/06/02/%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          技术技能
        
      </div>
    </a>
  
  
    <a href="/2020/06/02/tensorflow-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D,%E6%9C%89%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E8%B6%B3%E5%A4%9F%E4%BA%86/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">tensorflow-梯度下降,有这一篇就足够了</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/06/02/%E5%AE%9E%E7%8E%B0%E4%B8%8E%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/">实现与问题汇总</a>
          </li>
        
          <li>
            <a href="/2020/06/02/%E6%8A%80%E6%9C%AF%E6%8A%80%E8%83%BD/">技术技能</a>
          </li>
        
          <li>
            <a href="/2020/06/02/%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E20200430/">函数使用说明20200430</a>
          </li>
        
          <li>
            <a href="/2020/06/02/tensorflow-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D,%E6%9C%89%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E8%B6%B3%E5%A4%9F%E4%BA%86/">tensorflow-梯度下降,有这一篇就足够了</a>
          </li>
        
          <li>
            <a href="/2020/06/02/BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/">BP神经网络学习</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>